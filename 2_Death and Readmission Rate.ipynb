{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pyspark",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-851afb5d2792>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named pyspark"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pyspark import SparkContext\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output \n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output \n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "#  %pylab inline\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "import plotly\n",
    "# Set Plotly credetials\n",
    "\n",
    "plotly.tools.set_credentials_file(username='pparab', api_key='jgQSn7NrsQAUnpx26Aks')\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as plotly_tools\n",
    "import plotly.graph_objs as go\n",
    "from plotly.graph_objs import *\n",
    " #Sign in the plotly API\n",
    "py.sign_in(\"pparab\", \"jgQSn7NrsQAUnpx26Aks\")\n",
    "\n",
    "\n",
    "\n",
    "ReqData = \"/Users/pushparajparab/Desktop/Hospital_Revised_Flatfiles/Readmissions_and_Deaths_Hospital.csv\"\n",
    "df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load(ReqData)\n",
    "df.registerTempTable('Data')\n",
    "\n",
    "_selectedCat = [\"NA\"]\n",
    "_selectedMeasure = [\"NA\"]\n",
    "_d = []\n",
    "_s = []\n",
    "_text = []\n",
    "_name = []\n",
    "_d2 = []\n",
    "_s2 = []\n",
    "_text2 = []\n",
    "_name2 = []\n",
    "_d3 = []\n",
    "_s3 = []\n",
    "_text3 = []\n",
    "_name3 = []\n",
    "def on_change2(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        clear_output()\n",
    "        \n",
    "        del _d[:]\n",
    "        del _s[:]\n",
    "        del _text[:]\n",
    "        del _name[:]\n",
    "        del _d2[:]\n",
    "        del _s2[:]\n",
    "        del _text2[:]\n",
    "        del _name2[:]\n",
    "        del _d3[:]\n",
    "        del _s3[:]\n",
    "        del _text3[:]\n",
    "        del _name3[:]\n",
    "        data1= \"SELECT Denominator,Score,Compared_to_National,Hospital_Name from Data \"\n",
    "        data1+= \" where Measure_Name = '\"+ change['new'] + \"' \"\n",
    "        data1+= \" AND Compared_to_National = 'No Different than the National Rate' \"\n",
    "        categoryName = spark.sql(data1)\n",
    "        _dataList = categoryName.collect()\n",
    "   \n",
    "        for i in range(len(_dataList)):\n",
    "            _d.append(_dataList[i][0])\n",
    "            _s.append(_dataList[i][1])\n",
    "            _text.append(_dataList[i][2] + \", \" + _dataList[i][3])\n",
    "            _name.append(_dataList[i][3])  \n",
    "        data2= \"SELECT Denominator,Score,Compared_to_National,Hospital_Name from Data \"\n",
    "        data2+= \" where Measure_Name = '\"+ change['new'] + \"' \"\n",
    "        data2+= \" AND Compared_to_National = 'Worse than the National Rate' \"\n",
    "        categoryName2 = spark.sql(data2)\n",
    "        _dataList2 = categoryName2.collect()\n",
    "        \n",
    "#         categoryName2.show()\n",
    "        for i in range(len(_dataList2)):\n",
    "            _d2.append(_dataList2[i][0])\n",
    "            _s2.append(_dataList2[i][1])\n",
    "            _text2.append(_dataList2[i][2] + \", \" + _dataList2[i][3])\n",
    "            _name2.append(_dataList2[i][3])\n",
    "            \n",
    "        data3= \"SELECT Denominator,Score,Compared_to_National,Hospital_Name from Data \"\n",
    "        data3+= \" where Measure_Name = '\"+ change['new'] + \"' \"\n",
    "        data3+= \" AND Compared_to_National = 'Better than the National Rate' \"\n",
    "        categoryName3 = spark.sql(data3)\n",
    "        _dataList3 = categoryName3.collect()\n",
    "        \n",
    "#         categoryName2.show()\n",
    "        for i in range(len(_dataList3)):\n",
    "            _d3.append(_dataList3[i][0])\n",
    "            _s3.append(_dataList3[i][1])\n",
    "            _text3.append(_dataList3[i][2] + \", \" + _dataList3[i][3])\n",
    "            _name3.append(_dataList3[i][3])   \n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "def on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        clear_output()\n",
    "        _selectedCat[0] = (change['new'])  \n",
    "        _query_O = \"SELECT distinct Measure_Name from Data\" \n",
    "        if (change['new']) == \"Death Rate\" :\n",
    "            _query_O = _query_O +  \" WHERE Measure_ID LIKE '%MORT%'\"\n",
    "        else :\n",
    "            _query_O = _query_O +  \" WHERE Measure_ID LIKE '%READM%'\"\n",
    "            \n",
    "        TypeName = spark.sql(_query_O)  \n",
    "        _types = []\n",
    "        type_nameList = TypeName.collect();\n",
    "        for i in range(len(type_nameList)):\n",
    "            _types.append(type_nameList[i][0])\n",
    "        select1.options = _types\n",
    "           \n",
    " \n",
    "select = widgets.Dropdown(\n",
    "    options=[\"NA\",\"Death Rate\",\"Readmission Rate\"],\n",
    "    description='Category:',\n",
    "    disabled=False\n",
    ")\n",
    "display(select)\n",
    "\n",
    "select1 = widgets.Dropdown(\n",
    "        \n",
    "        description='Measure Name:',\n",
    "        disabled=False\n",
    "        )\n",
    "display(select1)\n",
    "select1.observe(on_change2) \n",
    "\n",
    "select.observe(on_change)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pparab/9.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace = go.Scatter(\n",
    "            x = _s,\n",
    "            y = _d,\n",
    "            mode = 'markers',\n",
    "            text = _text \n",
    "        )\n",
    "trace2 = go.Scatter(\n",
    "            x = _s2,\n",
    "            y = _d2,\n",
    "\n",
    "            mode = 'markers',\n",
    "            text = _text2 \n",
    "        )\n",
    "\n",
    "trace3 = go.Scatter(\n",
    "            x = _s3,\n",
    "            y = _d3,\n",
    "\n",
    "            mode = 'markers',\n",
    "            text = _text3 \n",
    "        )\n",
    "data = [trace,trace2,trace3]\n",
    "# Plot and embed in ipython notebook!\n",
    "py.iplot(data, filename='basic-scatter')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
